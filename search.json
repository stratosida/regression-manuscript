[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "This site contains supplemental material to support the IDA regression manuscript."
  },
  {
    "objectID": "Bact_suppl.html#overview",
    "href": "Bact_suppl.html#overview",
    "title": "IDA regression manuscript",
    "section": "Overview",
    "text": "Show the code\n# define key predictors without pseudo-log trafo ('orig') and transformed ('trans'), replace WBC with WBC_noNEU\nkey_predictors_orig  <- bact_variables$vip_vars %>%\n  str_replace('WBC', 'WBC_noNEU')\nkey_predictors_trans <- bact_transformed$vip_vars %>%\n  str_replace('WBC', 'WBC_noNEU')\n\n# include only complete cases\nmodel_df_complete <- c_bact[c('BC', unique(c(bact_variables$vip_vars, bact_transformed$vip_vars)))] %>%\n  mutate(\n    WBC_noNEU = WBC - NEU\n  ) %>%\n  na.omit\n\nmodel_df_complete <- model_df_complete %>%\n  mutate(\n    t_WBC_noNEU = pseudo_log(WBC_noNEU, ida_trans(model_df_complete$WBC_noNEU)$const) \n  )\n\nn_excl_cases <- dim(c_bact)[1] - dim(model_df_complete)[1] \npct_excl <- round((1-(dim(model_df_complete)[1] / dim(c_bact)[1])) * 100,1)\npct_complete <- dim(model_df_complete)[1] / dim(c_bact)[1] * 100\n\n\nIn the following examples we use the Bacteremia data with complete observations regarding the key predictors WBC_noNEU, Alter, BUN, KREA, NEU, PLT, which represent 93.9% of the whole dataset. We will fit a global logistic regression model with the outcome ‘BC’ and the key predictors as covariates. We will use pseudo-log transformations as suggested in the IDA. Within the model, all key predictors will be transformed by fractional polynomials of order 1 (df = 2).\nThe aim of the examples is to showcase how decisions derived from IDA influence the results of the fitted model."
  },
  {
    "objectID": "Bact_suppl.html#global-model",
    "href": "Bact_suppl.html#global-model",
    "title": "IDA regression manuscript",
    "section": "Global Model",
    "text": "The global model will be fitted by the mfp function. If not indicated otherwise, we will use the fp-transformations of the key predictors determined in global model in all consecutive models. For all models we report McFaddens’s R² and the AUC, i.e. the area under the ROC curve, and boxplots comparing BC predictions with outcomes.\n\nModel Summary\n\n\nShow the code\nglobal_formula <- paste0('BC ~ ', paste(paste0(paste0('fp(', key_predictors_trans), ',df=2)'), collapse = ' + '))\n\nfit_mfp_complete <- mfp(as.formula(global_formula),\n                        data = model_df_complete,\n                        family = binomial)\n\n# save global formula with fp-trafos\nglobal_formula_fp <- paste('BC ~ ', paste0(tidy(fit_mfp_complete)$term[-1], collapse = ' + '))\n\ntidy(fit_mfp_complete) %>%\n  gt_model_table(title = 'global model')\n\n\n\n\n\n  \n    \n      global model\n    \n    \n  \n  \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n    \n  \n  \n    (Intercept)\n−2.04\n0.38\n−5.33\n1.00 × 10−7\n    I((t_WBC_noNEU + 0.1)^0.5)\n−5.24\n0.26\n−20.40\n1.71 × 10−92\n    I((t_NEU + 0.1)^1)\n2.00\n0.16\n12.67\n8.39 × 10−37\n    I((Alter/100)^1)\n1.60\n0.21\n7.71\n1.25 × 10−14\n    I(t_KREA^1)\n0.60\n0.20\n2.98\n2.87 × 10−3\n    I(((PLT + 1)/100)^1)\n−0.08\n0.03\n−2.46\n1.38 × 10−2\n    I(t_BUN^1)\n0.23\n0.19\n1.22\n2.23 × 10−1\n  \n  \n  \n\n\n\n\nShow the code\n#Mc Fadden's R²\n#r_squared_mcfadden <- with(summary(fit_mfp_complete), 1 - deviance/null.deviance)\n\n#AUC\nAUC = auc(fit_mfp_complete$y, predict(fit_mfp_complete, type = 'response'))\n\np_model_complete <- logreg_summary_plot(fit_mfp_complete, 'global model')\n\np_model_complete\n\n\n\n\n\n\n\nFunctional forms of global model\nWe now take a look at the functional forms of the covariates in the global model, which are determined by the fp algorithm. Besides scaling factors, only for t_WBC_noNEU the fp algorithm chose a non-linear transformation (note the ‘^0.5’ in the term column). This means all other covariates enter the model in a linear fashion. In the following effect plots, each variable is adjusted to the median of the other variables in the model.\n\n\nShow the code\n# medians of all key predictors, selected variables will be adjusted to these medians in effect plots\nmodel_df_medians <- model_df_complete[,unique(c(key_predictors_orig, key_predictors_trans))] %>%\n  summarise_all(median)\n\nfor(i in 1:length(key_predictors_trans)){\n\n  new_data <- bind_cols(\n    model_df_medians,\n    x = model_df_complete[,key_predictors_trans[i]]\n    ) %>%\n    select(-key_predictors_trans[i]) %>%\n    as_tibble() %>%\n    distinct()\n  \n  pred_complete <- predict(fit_mfp_complete, \n                        newdata = new_data %>%\n                          rename(!!key_predictors_trans[i] := x),  # is needed so predict finds the variables\n                        type = 'link', se.fit = TRUE)\n\n  plot_df <- cbind(\n    new_data,\n    yhat = pred_complete$fit,\n    yhat.lwr = pred_complete$fit - 1.96*pred_complete$se.fit,\n    yhat.upr = pred_complete$fit + 1.96*pred_complete$se.fit\n    ) %>%\n    as_tibble() \n  \n  p <- plot_df %>% \n    ggplot(aes(x = x, y = yhat, ymin = yhat.lwr, ymax = yhat.upr)) +\n    geom_ribbon(alpha = .2, color = NA) +\n    geom_line() +\n    geom_rug(\n      data = fit_mfp_complete$X %>% as.data.frame, \n      aes_string(x = key_predictors_trans[i]), \n      inherit.aes = FALSE) +\n    labs(\n      y = 'log odds',\n      x = key_predictors_trans[i]\n    ) +\n    theme_minimal()\n  \n  print(p)\n  \n  if(key_predictors_trans[i] == 'PLT'){ p_effect_PLT <- p} # save for example 5\n}"
  },
  {
    "objectID": "Bact_suppl.html#example-1-to-transform-or-not-to-transform",
    "href": "Bact_suppl.html#example-1-to-transform-or-not-to-transform",
    "title": "IDA regression manuscript",
    "section": "Example 1: to transform or not to transform",
    "text": "Only for one out of the six key predictors did the fp algorithm chose a non-linear transformation. But out of those six variables, four were pseudo-log transformed before entering the model. In the first example we want to compare the global model to a model using the key predictors on their original scale.\n\n\nShow the code\n# fit the complete mfp model using only original, non-transformed variables\nfit_mfp_complete_notrans <- mfp(as.formula(global_formula %>% str_replace_all('t\\\\_', '')),\n                     data = model_df_complete,\n                     family = binomial)\n\ntidy(fit_mfp_complete_notrans) %>% gt_model_table('global model without pseudo-log tranformations')\n\n\n\n\n\n  \n    \n      global model without pseudo-log tranformations\n    \n    \n  \n  \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n    \n  \n  \n    (Intercept)\n−3.18\n0.28\n−11.17\n5.48 × 10−29\n    log((WBC_noNEU + 0.2))\n−1.25\n0.06\n−20.22\n5.92 × 10−91\n    I(((NEU + 0.1)/10)^0.5)\n1.52\n0.12\n12.99\n1.34 × 10−38\n    I((Alter/100)^1)\n1.64\n0.20\n8.26\n1.51 × 10−16\n    I(((PLT + 1)/100)^1)\n−0.08\n0.03\n−2.53\n1.13 × 10−2\n    I((BUN/10)^1)\n0.02\n0.02\n0.68\n5.00 × 10−1\n    I(KREA^-0.5)\n−0.77\n0.21\n−3.69\n2.20 × 10−4\n  \n  \n  \n\n\n\n\nNote the different fp-transformation arising when the key predictors are not pseudo-log transformed. On the original scale, three covariates instead of one now enter the model via a non-linear fp-transformation. This suggests that a transfromation prior to the regression model ‘outsources’ the need for transformations within the model. Now let us compare the model performances.\n\n\nShow the code\np_model_notrans <- logreg_summary_plot(fit_mfp_complete_notrans, 'global model \\nwithout pseudo-log \\ntransformations') # maybe side by side with global model?\n\np_model_complete + coord_cartesian(ylim = c(0,.8)) + p_model_notrans + theme(axis.title.y = element_blank()) + coord_cartesian(ylim = c(0,.8))\n\n\n\n\n\nWith regards to McFadden’s R² and the AUC, the differences between the two approaches is marginal.\nNext we will compare the differences of the functional forms in the two models for those covariates where a pseudo-log transformation was suggested in IDA. We will look at the log odds for bacteremia by each covariate on the original and the transformed scale, and compare the global model using the original and the pseudo-log transformed covariates. Each variable is adjusted for the median of all other variables used.\n\n\nShow the code\nfor(i in 1:length(key_predictors_trans)){\n  if(key_predictors_orig[i] != key_predictors_trans[i]){\n  \n    new_data <- bind_cols(\n      model_df_medians,\n      x_orig  = model_df_complete[,key_predictors_orig[i]],\n      x_trans = model_df_complete[,key_predictors_trans[i]]\n      ) %>%\n      select(-key_predictors_orig[i], -key_predictors_trans[i]) %>%\n      as_tibble() %>%\n      distinct()\n    \n    pred_trans <- predict(fit_mfp_complete, \n                          newdata = new_data %>%\n                            rename(  # is needed so predict finds the variables\n                              !!key_predictors_orig[i] := x_orig,\n                              !!key_predictors_trans[i] := x_trans), \n                          type = 'link', se.fit = TRUE)\n    pred_original <- predict(fit_mfp_complete_notrans, \n                             newdata = new_data %>%\n                               rename(\n                                 !!key_predictors_orig[i] := x_orig,\n                                 !!key_predictors_trans[i] := x_trans), \n                             type = 'link', se.fit = TRUE)\n    \n    plot_df <- cbind(\n      new_data,\n      yhat_original = pred_original$fit,\n      yhat.lwr_original = pred_original$fit - 1.96*pred_original$se.fit,\n      yhat.upr_original = pred_original$fit + 1.96*pred_original$se.fit,\n      yhat_trans = pred_trans$fit,\n      yhat.lwr_trans = pred_trans$fit - 1.96*pred_trans$se.fit,\n      yhat.upr_trans = pred_trans$fit + 1.96*pred_trans$se.fit\n      ) %>%\n      as_tibble() %>%\n      pivot_longer(\n        cols = contains('yhat')\n      ) %>%\n      separate(name, c('var', 'model'), sep = '_') %>%\n      pivot_wider(\n        names_from = 'var', values_from = 'value'\n      ) %>%\n      mutate(\n        model = case_when(\n          model == 'trans' ~ 'pseudo-log transformed',\n          model == 'original' ~ 'original scale'\n        )\n      )\n    \n    \n    p_original <- plot_df %>% \n      ggplot(aes(x = x_orig, y = yhat, ymin = yhat.lwr, ymax = yhat.upr, color = model, fill = model)) +\n      geom_ribbon(alpha = .2, color = NA) +\n      geom_line() +\n      geom_rug(data = fit_mfp_complete_notrans$X %>% as.data.frame, \n        aes_string(x = key_predictors_orig[i]), \n        inherit.aes = FALSE\n      ) +\n      labs(\n        y = 'log odds',\n        title = 'on original scale',\n        x = key_predictors_orig[i],\n        color = 'model with data on',\n        fill = 'model with data on'\n      ) +\n      theme_minimal() +\n      scale_color_ptol() +\n      scale_fill_ptol()\n    \n    p_trans <- plot_df %>%\n      ggplot(aes(x = x_trans, y = yhat, ymin = yhat.lwr, ymax = yhat.upr, color = model, fill = model)) +\n      geom_ribbon(alpha = .2, color = NA) +\n      geom_line() +\n      geom_rug(data = fit_mfp_complete$X %>% as.data.frame, \n        aes_string(x = key_predictors_trans[i]), \n        inherit.aes = FALSE\n      ) +\n      labs(\n        y = 'log odds',\n        title = 'on pseudo-log scale',\n        x = key_predictors_trans[i],\n        color = 'model with data on',\n        fill = 'model with data on'\n      ) +\n      theme_minimal() +\n      scale_color_ptol() +\n      scale_fill_ptol()\n    \n    p <- p_original + (p_trans +\n                    theme(\n                      axis.title.y = element_text(color = NA)\n                    )) +\n      plot_layout(guides = 'collect') +\n      plot_annotation(caption = 'adjusted to medians of all other covariates')  & \n      theme(legend.position = 'bottom')\n    \n    print(p)\n  }\n  \n}"
  },
  {
    "objectID": "Bact_suppl.html#example-2-the-support-of-a-model-determines-what-it-can-explain",
    "href": "Bact_suppl.html#example-2-the-support-of-a-model-determines-what-it-can-explain",
    "title": "IDA regression manuscript",
    "section": "Example 2: the support of a model determines what it can explain",
    "text": "Next we compare the global model to a model were for an important variable, in our case we chose age, the variable support is reduced to the central 50% of the data (i.e. data within the 25% and 75% quantiles). Again, in the reduced models we use the same fp-transformations as in the global model.\n\n\nShow the code\nm_pct <- .5\n\nsel_central <- (model_df_complete$Alter > quantile(model_df_complete$Alter, 0.5-m_pct/2)) & \n  (model_df_complete$Alter < quantile(model_df_complete$Alter, 0.5+m_pct/2)) #needed later\n\nset.seed(2)\nsel_sample <- as.logical(round(runif(dim(model_df_complete)[1]))) # 50% random selection, needed later\n\npred_complete <- predict(fit_mfp_complete, \n                         newdata = model_df_complete,\n                         type = 'response')\ny_complete <- fit_mfp_complete$y\n\npred_central <- predict(fit_mfp_complete, \n                         newdata = model_df_complete[sel_central,],\n                         type = 'response')\ny_central <- fit_mfp_complete$y[sel_central]\n\npred_sample <- predict(fit_mfp_complete, \n                         newdata = model_df_complete[sel_sample,],\n                         type = 'response')\ny_sample <- fit_mfp_complete$y[sel_sample]\n\n\nr_squared_efron <- function(y, prediction){\n  n <- length(y)\n  1-(((1/n)*sum((y-prediction)^2))/((1/n)*sum((y-mean(y))^2)))\n}\n\ntribble(\n  ~data, ~AUC, ~`sacled Brier score`,\n  'complete', auc(y_complete, pred_complete) %>% as.numeric(), cor(y_complete, pred_complete)^2,\n  'central 50%', auc(y_central, pred_central) %>% as.numeric(), cor(y_central, pred_central)^2,\n  '50% sample', auc(y_sample, pred_sample) %>% as.numeric(), cor(y_sample, pred_sample)^2,\n  ) %>%\n  gt() %>%\n  fmt_number(2, decimals = 3) %>%\n  fmt_number(3, decimals = 5)\n\n\n\n\n\n  \n  \n    \n      data\n      AUC\n      sacled Brier score\n    \n  \n  \n    complete\n0.732\n0.06456\n    central 50%\n0.723\n0.05321\n    50% sample\n0.737\n0.06587\n  \n  \n  \n\n\n\n\nShow the code\np_ex2 <- rbind(\n  tibble(\n    BC = y_complete,\n    prediction = pred_complete,\n    model = 'complete data'\n  ),\n  tibble(\n    BC = y_central,\n    prediction = pred_central,\n    model = 'within IQR (age)'\n  ),\n  tibble(\n    BC = y_sample,\n    prediction = pred_sample,\n    model = 'random 50% subsample'\n  )) %>%\n  mutate(model = factor(model, levels = c('complete data', 'within IQR (age)', 'random 50% subsample'))) %>%\n  ggplot(aes(x = factor(BC), y = prediction, group = BC)) +\n  geom_boxplot() + \n  facet_grid(~model) +\n  theme_minimal() +\n  labs(x = 'BC')\n\np_ex2"
  },
  {
    "objectID": "Bact_suppl.html#example-3-the-limits-of-mulitiple-imputation",
    "href": "Bact_suppl.html#example-3-the-limits-of-mulitiple-imputation",
    "title": "IDA regression manuscript",
    "section": "Example 3: the limits of mulitiple imputation",
    "text": "To show the effect of multiple imputation if the number of missing values is high, we construct a dataset with 50% artificially generated missing values in one variable. First, recall the output of the complete model, relying on the Bacteremia data with complete cases regarding the key predictors.\n\n\nShow the code\ntidy(fit_mfp_complete) %>% gt_model_table('global model')\n\n\n\n\n\n  \n    \n      global model\n    \n    \n  \n  \n    \n      term\n      estimate\n      std.error\n      statistic\n      p.value\n    \n  \n  \n    (Intercept)\n−2.04\n0.38\n−5.33\n1.00 × 10−7\n    I((t_WBC_noNEU + 0.1)^0.5)\n−5.24\n0.26\n−20.40\n1.71 × 10−92\n    I((t_NEU + 0.1)^1)\n2.00\n0.16\n12.67\n8.39 × 10−37\n    I((Alter/100)^1)\n1.60\n0.21\n7.71\n1.25 × 10−14\n    I(t_KREA^1)\n0.60\n0.20\n2.98\n2.87 × 10−3\n    I(((PLT + 1)/100)^1)\n−0.08\n0.03\n−2.46\n1.38 × 10−2\n    I(t_BUN^1)\n0.23\n0.19\n1.22\n2.23 × 10−1\n  \n  \n  \n\n\n\n\nCreatinine (‘KREA’) is significant at a level that might not survive substantial missingness. We thus create a dataset were we artificially introduce 50% missing creatinine values, missing completely at random.\n\n\nShow the code\n# create 50% missings for t_KREA\nset.seed(3) # with seed=3, z-statistic for t_KREA is 1.48\nmodel_df_missings <- model_df_complete %>%\n  mutate(\n    t_KREA = ifelse(\n      runif(dim(model_df_complete)[1]) < .5,  #~50%/50% TURE/FALSE\n      t_KREA,\n      NA\n    )\n  )\n\n\nNext we fit a ‘complete case’ model in the case of missing creatinine data, using the fp-transformations from the global model.\n\n\nShow the code\nfit_mfp_missing <- glm(as.formula(global_formula_fp), #use same fp-trafos as in global model\n                       data = model_df_missings,\n                       family = binomial)\n\n\nNow we impute the missing creatinine data using MICE with 50 imputations, fit the model using the fp-transformations from the global model and pool the results.\n\n\nShow the code\n# impute\nimp_data <- mice(model_df_missings %>%\n                   select(BC, key_predictors_trans), \n                 m=50, maxit = 50, method='pmm', seed = 1)\n\n# fit imputed data\nimp_fits <- with(imp_data,\n                 glm(as.formula(global_formula_fp), #use same fp-trafos as in global model\n                 family = binomial)\n  )\n\n# pooled results\nfit_pooled <- pool(imp_fits)\n\n\nWe now can compare the outputs of the complete model, the complete model with missing data (i.e. only half of the original complete data is used), and the imputed model.\n\n\nShow the code\nbind_rows(\n  tidy(fit_mfp_complete)  %>% mutate(model = 'global model'),\n  tidy(fit_mfp_missing) %>% mutate(model = 'missing, complete cases'),\n  summary(fit_pooled) %>% select(-df) %>% as_tibble() %>% mutate(model = 'missing, imputed')\n  ) %>%\n  relocate(term, model) %>%\n  arrange(term, model) %>%\n  group_by(term) %>%\n  group_by(term_old = term) %>%\n  mutate(\n    term = c(unique(term_old), rep('', n()-1))\n  ) %>%\n  ungroup %>%\n  select(-term_old) %>%\n  gt %>%\n  fmt_number(\n    3:5,\n    decimals = 3\n  ) %>%\n  fmt_scientific(6)\n\n\n\n\n\n  \n  \n    \n      term\n      model\n      estimate\n      std.error\n      statistic\n      p.value\n    \n  \n  \n    (Intercept)\nglobal model\n−2.036\n0.382\n−5.326\n1.00 × 10−7\n    \nmissing, complete cases\n−2.601\n0.541\n−4.806\n1.54 × 10−6\n    \nmissing, imputed\n−2.069\n0.384\n−5.385\n7.36 × 10−8\n    I(((PLT + 1)/100)^1)\nglobal model\n−0.079\n0.032\n−2.462\n1.38 × 10−2\n    \nmissing, complete cases\n−0.118\n0.046\n−2.544\n1.10 × 10−2\n    \nmissing, imputed\n−0.078\n0.032\n−2.439\n1.48 × 10−2\n    I((Alter/100)^1)\nglobal model\n1.601\n0.208\n7.711\n1.25 × 10−14\n    \nmissing, complete cases\n1.910\n0.296\n6.443\n1.17 × 10−10\n    \nmissing, imputed\n1.591\n0.210\n7.573\n3.91 × 10−14\n    I((t_NEU + 0.1)^1)\nglobal model\n2.000\n0.158\n12.673\n8.39 × 10−37\n    \nmissing, complete cases\n2.113\n0.225\n9.375\n6.94 × 10−21\n    \nmissing, imputed\n1.998\n0.158\n12.644\n0.00\n    I((t_WBC_noNEU + 0.1)^0.5)\nglobal model\n−5.236\n0.257\n−20.399\n1.71 × 10−92\n    \nmissing, complete cases\n−5.007\n0.366\n−13.677\n1.39 × 10−42\n    \nmissing, imputed\n−5.221\n0.256\n−20.355\n0.00\n    I(t_BUN^1)\nglobal model\n0.226\n0.185\n1.220\n2.23 × 10−1\n    \nmissing, complete cases\n0.401\n0.264\n1.519\n1.29 × 10−1\n    \nmissing, imputed\n0.302\n0.227\n1.332\n1.84 × 10−1\n    I(t_KREA^1)\nglobal model\n0.598\n0.201\n2.982\n2.87 × 10−3\n    \nmissing, complete cases\n0.429\n0.289\n1.485\n1.38 × 10−1\n    \nmissing, imputed\n0.483\n0.277\n1.745\n8.25 × 10−2\n  \n  \n  \n\n\n\n\nThe z-statistic for creatinine drops from 2.98 to 1.49 when half the data is missing. Also in other variables the z-statistic is less extreme in the ‘missing, complete case analysis’ compared to the global model. The interesting observations is that MI recreates estimates and standard errors very close to the global model in most variables, but not in the one that was being imputed, namely creatinine. In variable selection, chreatinine, which is highly significant in the ‘true’ model, is likely to be dropped, based on the imputed data.\n\n\nShow the code\n#pearson & spearman correalation of CREA and BUN\n\nr_pearson  <- cor(model_df_complete$t_KREA, model_df_complete$BUN, method = 'pearson') %>% round(3)\nr_spearman <- cor(model_df_complete$t_KREA, model_df_complete$BUN, method = 'spearman') %>% round(3)"
  },
  {
    "objectID": "Bact_suppl.html#example-4-interpretation-of-regression-coefficient-size",
    "href": "Bact_suppl.html#example-4-interpretation-of-regression-coefficient-size",
    "title": "IDA regression manuscript",
    "section": "Example 4: Interpretation of regression coefficient ‘size’",
    "text": "The variables WBC_noNEU and t_WBC_noNEU are on two very different scales:\n\n\nShow the code\np_ex4 <- model_df_complete %>%\n  select(key_predictors_trans[str_detect(key_predictors_trans, 't_')]) %>%\n  mutate_all(as.numeric) %>%\n  pivot_longer(cols = everything()) %>%\n  ggplot(aes(x = value, group = name)) + \n  facet_wrap(~name, scales = 'free', strip.position = \"bottom\") +\n  geom_histogram(fill = 'firebrick2', color = NA, alpha = 0.5) +\n  theme_minimal() +\n  theme(strip.placement = 'outside')\n\np_ex4\n\n\n\n\n\nShow the code\n# standardized regression coefficients\n\ntidy(fit_mfp_complete) %>%\n  select(term, estimate) %>%\n  filter(term != '(Intercept)') \n\n\n# A tibble: 6 × 2\n  term                       estimate\n  <chr>                         <dbl>\n1 I((t_WBC_noNEU + 0.1)^0.5)  -5.24  \n2 I((t_NEU + 0.1)^1)           2.00  \n3 I((Alter/100)^1)             1.60  \n4 I(t_KREA^1)                  0.598 \n5 I(((PLT + 1)/100)^1)        -0.0789\n6 I(t_BUN^1)                   0.226 \n\n\nShow the code\nmodel_df_complete %>%\n  summarise(\n    WBC_noNEU = sd(((t_WBC_noNEU + 0.1)^0.5) * fit_mfp_complete$coefficients[2]),\n    NEU = sd((t_NEU + 0.1) * fit_mfp_complete$coefficients[3]),\n    Age = sd((Alter / 100) * fit_mfp_complete$coefficients[4]),\n    CREA = sd((t_KREA) * fit_mfp_complete$coefficients[5]),\n    PLT = sd(((PLT + 1) / 100) * fit_mfp_complete$coefficients[6]),\n    BUN = sd((t_BUN) * fit_mfp_complete$coefficients[7])\n  ) %>%\n  pivot_longer(cols = everything(), names_to = 'variable', values_to = 'standardized beta') %>%\n  gt %>%\n  fmt_number(\n    2, decimals = 4\n  )\n\n\n\n\n\n  \n  \n    \n      variable\n      standardized beta\n    \n  \n  \n    WBC_noNEU\n0.7029\n    NEU\n0.4551\n    Age\n0.2912\n    CREA\n0.1310\n    PLT\n0.0959\n    BUN\n0.0623\n  \n  \n  \n\n\n\n\nLet us recall the two estimates to the covariates WBC_noNEU and t_WBC_noNEU.\n\n\nShow the code\nbind_rows(\n  tidy(fit_mfp_complete) %>% select(term, estimate),\n  tidy(fit_mfp_complete_notrans) %>% select(term, estimate)\n  ) %>% \n  filter(str_detect(term, 'WBC')) %>%\n  gt %>%\n  fmt_number(2, decimals = 2)\n\n\n\n\n\n  \n  \n    \n      term\n      estimate\n    \n  \n  \n    I((t_WBC_noNEU + 0.1)^0.5)\n−5.24\n    log((WBC_noNEU + 0.2))\n−1.25\n  \n  \n  \n\n\n\n\n(Suggestion: show this with models without fp trafo?)\nBecause the fp-transformations further complicate the interpretation of the regression coefficients, let us consider two logisitc regression models with WBC_noNEU and t_WBC_noNEU as single covariate, respectively.\n\n\nShow the code\nfit_wbc_orig <- glm(BC ~ WBC_noNEU,\n                    data = model_df_complete,\n                    family = binomial) \n\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\nShow the code\nfit_wbc_trans <- glm(BC ~ t_WBC_noNEU,\n                     data = model_df_complete,\n                     family = binomial) \n\nbind_rows(\n  tidy(fit_wbc_orig),\n  tidy(fit_wbc_trans)\n  ) %>%\n  filter(str_detect(term, 'WBC')) %>%\n  select(term, estimate) %>%\n  gt %>%\n  fmt_number(estimate, decimals = 2)\n\n\n\n\n\n  \n  \n    \n      term\n      estimate\n    \n  \n  \n    WBC_noNEU\n−0.56\n    t_WBC_noNEU\n−2.91\n  \n  \n  \n\n\n\n\nShow the code\nfit_wbc_orig$coefficients[2] %>% round(2)\n\n\nWBC_noNEU \n    -0.56 \n\n\nThe estimates -0.56 and -2.91 denote the change in log odds for the outcome when the ‘term’ variable changes by 1 unit, but cannot be compared directly. A \\(1\\) unit change is only a small step on the original scale, where WBC_noNEU covers values from -0.15 up to 152.74. In comparison, t_WBC_noNEU lies between -0.06 up to 2.45, so change of \\(1\\) unit cover almost half the range of the variable."
  },
  {
    "objectID": "Bact_suppl.html#example-5-plot-of-functional-form-should-be-resticted-to-areas-with-high-density",
    "href": "Bact_suppl.html#example-5-plot-of-functional-form-should-be-resticted-to-areas-with-high-density",
    "title": "IDA regression manuscript",
    "section": "Example 5: Plot of functional form should be resticted to areas with high density",
    "text": "The functional forms have wide confidence intervals when the data is sparse. In presentations of the effects, plots of the functional forms can be limited to areas with high density. In this analysis, PLT was very sparse above ~800 [UNITS], which is reflected in a large confidence interval for high PLT values. In the effect plot PLT values could be limited to values <800 [UNITS].\n\n\nShow the code\nfit_linear_complete <- glm(as.formula(paste0('BC ~ ', paste(key_predictors_trans, collapse = '+'))),\n                           data = model_df_complete,\n                           family = 'binomial') \n\nnew_data <- bind_cols(\n  model_df_medians[,names(model_df_medians) != 't_WBC_noNEU'],\n  t_WBC_noNEU = model_df_complete[,'t_WBC_noNEU']\n  ) %>%\n  as_tibble() %>%\n  distinct()\n\npred_linear <- predict(fit_linear_complete,\n                       newdata = new_data,  # is needed so predict finds the variables\n                      type = 'link', se.fit = TRUE)\n\npred_complete <- predict(fit_mfp_complete, \n                      newdata = new_data,  # is needed so predict finds the variables\n                      type = 'link', se.fit = TRUE)\n\nplot_df <- \n  rbind(\n    cbind(\n      new_data,\n      yhat = pred_linear$fit,\n      yhat.lwr = pred_linear$fit - 1.96*pred_linear$se.fit,\n      yhat.upr = pred_linear$fit + 1.96*pred_linear$se.fit,\n      model = 'linear'\n      ),\n    cbind(\n      new_data,\n      yhat = pred_complete$fit,\n      yhat.lwr = pred_complete$fit - 1.96*pred_complete$se.fit,\n      yhat.upr = pred_complete$fit + 1.96*pred_complete$se.fit,\n      model = 'mfp'\n      )\n  ) %>%\n  as_tibble() \n\np_ex5 <- plot_df %>% \n  ggplot(aes(x = t_WBC_noNEU, y = yhat, ymin = yhat.lwr, ymax = yhat.upr, color = model, group = model)) +\n  geom_ribbon(alpha = .2, color = NA) +\n  geom_line(size = 1) +\n  geom_rug(\n    data = fit_mfp_complete$X %>% as.data.frame, \n    aes(x = t_WBC_noNEU), \n    inherit.aes = FALSE) +\n  labs(\n    y = 'log odds'\n  ) +\n  theme_minimal() +\n  scale_color_ptol()\n\n\nlogreg_summary_plot(fit_linear_complete, 'linear model')\n\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls < cases\n\n\nDon't know how to automatically pick scale for object of type labelled/integer. Defaulting to continuous.\n\n\n\n\n\nShow the code\np_ex5  + (p_ex5 + coord_cartesian(xlim = quantile(model_df_complete$t_WBC_noNEU, c(.05,.95)), ylim = c(-4.5, -0.5))) +\n  plot_layout(guides = 'collect')\n\n\n\n\n\n\n\nShow the code\n#p_effect_PLT + p_effect_PLT + coord_cartesian(xlim = c(0,800)) # not working because of ggplot bug\n\n#workaround because of ggplot bug\np_effect_PLT + geom_ribbon(fill = gray(.9)) + geom_line() + \n  p_effect_PLT + \n    coord_cartesian(xlim = c(0,800)) + \n    geom_ribbon(fill = gray(.9)) + \n    geom_line() +\n    theme(axis.title.y = element_blank())"
  }
]